# Быстрый поиск всех простых циклов в графе
Проснулся я как-то ближе к вечеру и решил — всё пора, пора уже сделать Graph API в моем библиотеке, что за библиотека об этом ниже. А за одно и проверку графа на циклы починить и ускорить. Сделал я Graph API, улучшил код, сделал представление графа в удобном виде, и дошёл до задачи нахождения всех циклов. Открыл гугл набрал "поиск всех простых циклов в графе" и увидел...

А увидел я следующее:
* [Ссылку на codeforce](http://codeforces.com/blog/entry/12141?locale=ru) - но алгоритм не работает, да и обычный [поиск в глубину](https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D0%B8%D1%81%D0%BA_%D0%B2_%D0%B3%D0%BB%D1%83%D0%B1%D0%B8%D0%BD%D1%83#:~:text=%D0%9F%D0%BE%D0%B8%D1%81%D0%BA%20%D0%B2%20%D0%B3%D0%BB%D1%83%D0%B1%D0%B8%D0%BD%D1%83%20(%D0%B0%D0%BD%D0%B3%D0%BB.,%D0%B8%D1%81%D1%85%D0%BE%D0%B4%D1%8F%D1%89%D0%B8%D0%B5%20%D0%B8%D0%B7%20%D1%80%D0%B0%D1%81%D1%81%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D0%B2%D0%B0%D0%B5%D0%BC%D0%BE%D0%B9%20%D0%B2%D0%B5%D1%80%D1%88%D0%B8%D0%BD%D1%8B%20%D1%80%D1%91%D0%B1%D1%80%D0%B0.)
* Нашёл другой [алгоритм](https://vscode.ru/prog-lessons/poisk-elementarnyih-tsiklov-v-grafe.html), тоже обычный поиск в глубину.
* Куча намеком, что циклов в графе может быть много, и в общем случае задача не решаемая за приемлимое время.
* Всё... 

Но я то знаю что в рамках моей задачи найти все циклы должно быть возможным за маленькое время, без супер компьютеров - не тот порядок величин. 

Чуть пониже конкретные цифры, а вначале поймем о чем речь.

## Что за библиотека?
Библиотека называется [DITranquillity](https://github.com/ivlevAstef/DITranquillity) написана на языке Swift, и её задача - внедрять зависимости. С задачей внедрения зависимостей библиотека справляется на ура, имеет возможности которые не умеют другие библиотеки на Swift, и делает это с хорошей скоростью.

## Но зачем мне взбрело проверять циклы в графе зависимостей?

Одной из особенностей библиотеки, является функция проверки графа зависимостей. Это набор разных проверок, которые позволяют избежать проблем во время исполнениях, что экономит время разработки. И проверка на циклы выделяется отдельно среди этих проверок, так как эта операция занимает гораздо больше времени, и до недавнего времени на среднем проекте уже становилась бесполезной.

О проблеме я знал давно, но понимал, что в том виде в каком сейчас хранится граф сделать быструю проверку сложно. Да и раз уж библиотека умеет проверяь граф зависимостей, то сделать Graph API само напрашивается. Graph API - позволяет отдавать граф зависимостей для внешнего пользования, для того чтобы:
* Его проанализировать как-то на свой лад. Например, я для работы собрал автоматически все зависимости между нашими модулями, что помогло убрать лишние зависимости и ускорить сборку.
* Пока нет, но когда-нибудь будет - визуализация этого графа с помощью graphvis.
* И проверка циклов.

Особенно ради второго - кто как, а мне нравится смотреть на эти ужасные картинки и понимать как же все плохо...

## Исходные данные
Давайте посмотрим с чем предстоит работать:
* macbook pro 2019, 2,6 GHz 6-Core i7, 32 Gb, Xcode 11.4, Swift 5.2
* Проект на языке Swift с 300к+ строчек кода (пустые строки и комментарии не в счёт)
* Более 900 вершин
* Более 2000 ребер
* Максимальная глубина зависимостей достигает 40
* Почти 7000 циклов

Все замеры делаются в debug режиме, не в release, так как использовать проверку графа будут только в дебаге.

Время проверки составляло 95 минут.

///
Для не терпеливых
После оптимизации время проверки уменьшилось до 3 секунд, то есть ускорение составило три порядка.
///

С задаче все ясно, с данными тоже, переходим к решению.

# Этап 1. Представление графа
Граф зависимостей он ориентированный. Каждая вершина это компонент, ну или по другому информация о классе - как его создавать, как его искать, какие зависимости он имеет. И до появления Graph API компоненты хранились в словаре который по запрашиваемому типу возвращал список подходящих компонент. Понятное дело каждый раз для каждой вершины искать в словаре это не быстро, поэтому надо было представить граф в удобном виде.

Существует много вариантов представления графа:
* Список ребер - отдельно храним вершины отдельно храним ребра
* Матрица смежности - для каждой вершины храним информацию есть ли переход в другую вершину
* Список смежности - для каждой вершины храним список переходов

Это только наиболее популярные. И даже эти представления можно реализовать по разному. 

Первым делом глаз пал на матрицу смежности. Но потом осознал, что информация о входящих ребрах нужна редко, а вот информация о исходящих ребрах часто. По этим причинам перешел на список смежности - В нем сложно найти входящие ребра, но зато быстрее просматривать все исходящие ребра. Ну и памяти меньше занимает.

А выражаясь псевдо языком программирования граф хранится так:
```
Graph:
	vertices: [Vertex]
	adjacencyList: [[Edge]]

Vertex:
	more information about vertex

Edge:
	toIndices: [Int]
	information about edge
```
Где Vertex информация о вершине, а Edge информация о переходе в том числе и индексы куда по данному ребру можно перейти. 
Обращаю внимание что ребро хранит переход не один в один, а один в много. Это сделано специально, чтобы обеспечить уникальность рёбер, что в случае зависимостей очень важно, так как два перехода на две вершины, и один переход на две вершины означает разные вещи.

# Этап 2. Наивный поиск в глубину
Как говорил мой учитель - "прежде чем оптимизировать, убедись, что это необходимо". Поэтому первым делом я написал обычный поиск в глубину:
```
func findAllCycles() -> [Cycle] {
	result: [Cycle] = []
	for index in vertices {
     	result += findCycles(from: index)
    }

    return result
}

func findCycles(from index: Int) -> [Cycle] {
	result: [Cycle] = []
	dfs(startIndex: index, currentIndex: index, visitedIndices: [], result: &result)

    return result
}

func dfs(startIndex: Int,
         currentIndex: Int,
         // visitedIndices каждый раз копируется
         visitedIndices: Set<Int>,
         // result всегда один - это ссылка
         result: ref [Cycle]) {
    if currentIndex == startIndex && !visitedIndices.isEmpty {
      result.append(cycle)
      return
    }

    if visitedIndices.contains(currentIndex) {
      return
    }

    visitedIndices += [currentIndex]

    for toIndex in adjacencyList[currentIndex] {
        dfs(startIndex: startIndex, currentIndex: toIndex, visitedIndices: visitedIndices, result: &result)
    }
}
```
Запустил этот алгоритм, подождал 15-20 минут, не дождался завершения, огорчился, понял, что так дело не пойдет.

А почему так долго? Про размер графа я уже писал, но в чем проблема данного алгоритма? А проблема в том, что для многих вершин количество вызовов функции dfs сотавляет миллион, а у некоторых по 30миллионов раз. То есть в среднем 900 вершин * 1000000 = 900.000.000 вызовов функции dfs... 

Былобы тут дерево, тогда бы функция вызывалась для каждой вершины не более 900 раз, но наличие циклов приводит к тому, что каждую вершину можно пройти по 1,2,3,... раз. И зависимость далеко не линейна от количества циклов.

Как будем оптимизировать?

# Этап 3. Наивная оптимизация
В предыдущей реализации ищутся циклы только проходящие через указанную вершину, а все подциклы найденные при поиске основного цикла просто игнорируются. Возникает желание перестать их игнорировать - ведь тогда получается, что можно выкидывать из рассмотрения все вершины через которые мы уже прошли. Сделать это не так сложно, поэтому будем пробовать:
```
func findAllCycles() -> [Cycle] {
	globalVisitedIndices: Set<Int> = []
	result: [Cycle] = []
	for index in vertices {
		if globalVisitedIndices.containts(index) {
			continue
		}
      	result += findCycles(from: index, globalVisitedIndices: &globalVisitedIndices)
    }

    return result
}

func findCycles(from index: Int, globalVisitedIndices: ref Set<Int>) -> [Cycle] {
	result: [Cycle] = []
	dfs(currentIndex: index, visitedIndices: [], globalVisitedIndices, &globalVisitedIndices, result: &result)

    return result
}

func dfs(currentIndex: Int,
         // visitedIndices каждый раз копируется
         visitedIndices: Set<Int>,
         // globalVisitedIndices всегда один - это ссылка
         globalVisitedIndices: ref Set<Int>,
         // result всегда один - это ссылка
         result: ref [Cycle]) {

    if visitedIndices.contains(currentIndex) {
    	// если visitedIndices упорядочен, то можно вырезать кусок тем самым получив информацию о цикле
    	result.append(cycle)
      return
    }

    visitedIndices += [currentIndex]

    for toIndex in adjacencyList[currentIndex] {
        dfs(currentIndex: toIndex, visitedIndices: visitedIndices, globalVisitedIndices: &globalVisitedIndices, result: &result)
    }
}
```
К сожалению такая реализация тоже не устроила меня по времени, так как за 10минут я не дождался окончания. У нее несколько проблем:
* Если у меня несколько раздельных больших циклов, то на каждый такой цикл тратиться уйму времени хоть и один раз всего.
* Многие циклы "дублируются" - нужно при добавление проверять уникальность.

Я решил, что первый вариант мне нравится больше - он понятней для анализа, так как мы запоминаем циклы для конкретной вершины, а не для всего подрят.

# Этап 4. А что если отсекать листья из поиска
Ну раз при первично анализе у нас видно что есть невероятно большое количество вызовов функции dfs, но не так много циклов, то значит есть листовые подветки, которые мы часто проходим, но которые заведомо не находятся в цикле. Давайте их отсекать.
Радостно быстро написал новый код, запустил - ого быстро работает. Вот только циклов стало в разы меньше... Разбираемся в чем проблема? - Ага, проблема вот тут:
```
if visitedIndices.contains(currentIndex) {
```
Я решил, что в этом случае мы тоже наткнулись на лист, но это не верно. Давайте рассмотрим вот такой граф:
-----(картинка Graph.png)A->B, A->C, B->E, B->D, C->B, E->C, D->A
В этом графе есть подцикл B->E->C значит этот if выполнится. Теперь предположим, что вначале мы идем так:
A->B->E->C->B!. При таком проходе C, Е помечается как лист. После находим цикл A->B->D->A.
Но Цикл A->C->B->D->A будет упущен, так как вершина C почена как лист.

Если это исправить и отбрасывать только листовые подветки, то количество вызовов dfs снижается, но не значительно.

# Этап 5. Делаем подготовку к поиску
Я решил немного проанализировать цифры которые получается на первом варианте dfs. И Увидел, частую ситуацию когда находится 1-2 цикла, но при этом просматривается функция dfs вызывается 30миллионов раз.
Такое возможно в случаях на подобии:
-----(картинка GraphBig.png)A -> B, B -> A, B -> C, C -> большой граф с кучей циклов в том числе и на C. 
Где "Big" это какой-то большой граф с кучей циклов, но не имеющий цикла на A.

И тут возникает идея! Для этого большого графа с циклами, можно заранее узнать, что он не имеет переходов на A или B, а значит сразу при переходе на C будет известно, что эту вершину не имеет смысла рассматривать, так как из нее нельзя попасть в A.

Как это узнать заранее? Достаточно для каждой вершины запустить или поиск в глубину, или в ширину, но при этом отсекать повторные переходы полностью. И сохранять все посещенные вершины. Такой поиск в худшем случае на полном графе займет N^2 времени, а на реальных данных намного меньше. 

Меняем код под новую идею:
```
func findAllCycles() -> [Cycle] {
	reachableIndices: [Set<Int>] = findAllReachableIndices()
	result: [Cycle] = []
	for index in vertices {
     	result += findCycles(from: index, reachableIndices: &reachableIndices)
    }

    return result
}

func findAllReachableIndices() -> [Set<Int>] {
	reachableIndices: [Set<Int>] = []
	for index in vertices {
      reachableIndices[index] = findAllReachableIndices(for: index)
    }
    return reachableIndices
}

func findAllReachableIndices(for startIndex: Int) -> Set<Int> {
    visited: Set<Int> = []
    stack: [Int] = [startIndex]
    while fromIndex = stack.popFirst() {
      visited.insert(fromIndex)

      for toIndex in adjacencyList[fromIndex] {
        if !visited.contains(toIndex) {
          stack.append(toIndex)
        }
      }
    }

    return visited
}

func findCycles(from index: Int, reachableIndices: ref [Set<Int>]) -> [Cycle] {
	result: [Cycle] = []
	dfs(startIndex: index, currentIndex: index, visitedIndices: [], reachableIndices: &reachableIndices, result: &result)

    return result
}

func dfs(startIndex: Int,
         currentIndex: Int,
         visitedIndices: Set<Int>,
         reachableIndices: ref [Set<Int>],
         result: ref [Cycle]) {
    if currentIndex == startIndex && !visitedIndices.isEmpty {
      result.append(cycle)
      return
    }

    if visitedIndices.contains(currentIndex) {
      return
    }

    if !reachableIndices[currentIndex].contains(startIndex) {
    	return
    }

    visitedIndices += [currentIndex]

    for toIndex in adjacencyList[currentIndex] {
        dfs(startIndex: startIndex, currentIndex: toIndex, visitedIndices: visitedIndices, result: &result)
    }
}
```

Подобное операция позволяет уменьшить на два порядка количество вызовов функции dfs, а в некоторых случаях и вовсе избежать проверок. Но к сожалению даже так поиск всех циклов работает не быстро. Да это не 30миллионов вызов функции для одной вершины, а всеголишь 300тысяч, но это всеравно много. Но эо первый раз когда я дождался окончания - понадобилось 15минут на то чтобы найти все циклы с такой оптимизацией.

# Этап 6. Можно ли использовать прошлый результаты?
Чтобы дойти до этой простейшей идеи, мне понадобилось сделать три итерации каждая из которых была оптимальней предыдущей. 
Все началось с вопроса - "Зачем начинать поиск с новой вершины, если все исходящие ребра ведут в вершины которые или не содержат цикла, или это вершина через которую уже были построены все циклы?". Потом поток мыслей дошел до того что проверку можно делать рекурсивно. Это позволило уменьшить время до 5 минут.

И только потом я осознал, что эту проверку можно вставить прям внутри поиска в глубину:
```
func findAllCycles() -> [Cycle] {
	reachableIndices: [Set<Int>] = findAllReachableIndices()
	result: [Cycle] = []
	for index in vertices {
     	result += findCycles(from: index, reachableIndices: &reachableIndices)
    }

    return result
}

func findAllReachableIndices() -> [Set<Int>] {
	reachableIndices: [Set<Int>] = []
	for index in vertices {
      reachableIndices[index] = findAllReachableIndices(for: index)
    }
    return reachableIndices
}

func findAllReachableIndices(for startIndex: Int) -> Set<Int> {
    visited: Set<Int> = []
    stack: [Int] = [startIndex]
    while fromIndex = stack.popFirst() {
      visited.insert(fromIndex)

      for toIndex in adjacencyList[fromIndex] {
        if !visited.contains(toIndex) {
          stack.append(toIndex)
        }
      }
    }

    return visited
}

func findCycles(from index: Int, reachableIndices: ref [Set<Int>]) -> [Cycle] {
	result: [Cycle] = []
	dfs(startIndex: index, currentIndex: index, visitedIndices: [], reachableIndices: &reachableIndices, result: &result)

    return result
}

func dfs(startIndex: Int,
         currentIndex: Int,
         visitedIndices: Set<Int>,
         reachableIndices: ref [Set<Int>],
         result: ref [Cycle]) {
    if currentIndex == startIndex && !visitedIndices.isEmpty {
      result.append(cycle)
      return
    }

    if visitedIndices.contains(currentIndex) {
      return
    }

    if currentIndex < startIndex || !reachableIndices[currentIndex].contains(startIndex) {
    	return
    }

    visitedIndices += [currentIndex]

    for toIndex in adjacencyList[currentIndex] {
        dfs(startIndex: startIndex, currentIndex: toIndex, visitedIndices: visitedIndices, result: &result)
    }
}
```
Это одно условие написанное внутри dfs позволяет сократить время на два порядка - до 6 секунд.

А проверка то лежала на поверхности - Если уже найдены все циклы проходящие через вершину A, то при поиске циклов проходящие через любые другие вершины, рассматривать вершину A не имеет более смысла. Так-как уже найдены все циклы через A, а значит нельзя найти новых циклов через неё.

Такая проверка не только сильно ускоряет работу, но и полностью устраняет появление дублей, без необходимости их обрезать/сравнивать.
Что позволяет сэкономить время на способе хранения циклов - можно или вообще не хранить их или хранить в обычном массиве, а не множестве. Это экономит еще 5-10% времени исполнения.

# Этап 6. Профайл
Результат в 5-6 секунд меня уже устраивал, но хотелось еще быстрее. Поэтому я открыл профайл, в дебаг режиме. Да на языке Swift низкоуровневая оптимизация почти невозможна, но иногда находишь проблемы в неожиданных местах.

Одно из таких мест оказались логи - была допущена ошибка, из-за которой строковое выражение для логов считалось всегда, даже если оно потом не печаталось. Исправление этого косяка привело к тому, что скорость проверки уменьшилась до 3 секунд.

Ну и на удивление нашлось еще не значительное место которое позволило еще сэкономить 8-10% времени.
было (язык Swift):
```Swift
var visited: Set<Int> = []
var stack: [Int] = [startVertexIndex]
while let fromIndex = stack.first {
    stack.removeFirst()

    visited.insert(fromIndex)
    for toIndex in graph.adjacencyList[fromIndex].flatMap({ $0.toIndices }) {
        if !visited.contains(toIndex) {
            stack.append(toIndex)
        }
    }
}

return visited
```
cтало (язык Swift):
```Swift
var visited: Set<Int> = []
var stack: [Int] = [startVertexIndex]
while let fromIndex = stack.popLast() {
    visited.insert(fromIndex)
    for toIndex in graph.adjacencyList[fromIndex].flatMap({ $0.toIndices }) {
        if !visited.contains(toIndex) {
            stack.insert(toIndex, at: 0)
        }
    }
}

return visited
```
Вроде изменения не значительные, и кажется, что второй код должен работать медленнее - вставка элемента в начало массива должна занимать больше времени чем в конец. Но это особенность реализации массива в языке Swift - их хранение сделано так, что вставка в начало и в конец происходит за константное время.

# Итоги
А какие итоги могут быть? Цифры говорят сами за себя - было 95 минут, стало 2.5-3 секунды, да еще и добавилось новых проверок. 

Три секунды тоже выглядит не шустро, но не стоит забывать, что это на большом и не красивом графе зависимостей - такие днем с огнем не сыщешь в мобильной разработке.
Да и на другом проекте который больше похож на средний мобильный проект, время с 15 минут уменьшилось до менее секунды, при этом на более слабом железе.

А статья появилась просто из-за гугла - который не захотел мне помогать.

# Немного рекламы и Планы
Кому понравилась статья или не понравилась пожалуйста зайдите на страничку [библиотеки](https://github.com/ivlevAstef/DITranquillity) и поставьте ей звездочку.

Я каждый раз озвучиваю планы по развитию, каждый раз говорю "скоро" и всегда скоро оказывается когда-нибудь. Поэтому сроков называть не буду, но когда-нибудь это появится:
* Конвертация графа зависимостей в формат для graphvis - а он в свою очередь позволит просматривать графы визуально.
* Оптимизация основного функционала библиотеки - к сожалению с появлением большого количества новых функций, моя библиотека хоть и осталось быстрой, но теперь она не сверх быстрая, а на уровне других библиотек.
* Переход на проверку графа и поиск проблем во время компиляции, а не при запуске приложения.


P.S. Если отключить 5 этап полностью, то скорость работы понизится в 1.5 раза - до 4.5 секунд.
P.P.S. Статья написана так, будно это заняло вечность. На самом деле весь код, вместе с черновиком статьи был написан за двое выходных, по 4 часа в день.